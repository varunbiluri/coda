# Coda Environment Configuration
# Copy this file to .env and configure your settings

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# Server host and port
CODA_HOST=0.0.0.0
CODA_PORT=8000

# =============================================================================
# LLM CONFIGURATION
# =============================================================================

# Use mock LLM for development/testing (set to true to avoid API costs)
USE_MOCK_LLM=false

# LiteLLM provider and model configuration
LITELLM_PROVIDER=openai
LITELLM_MODEL=gpt-3.5-turbo

# =============================================================================
# API CREDENTIALS (Choose one provider)
# =============================================================================

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Azure OpenAI Configuration
AZURE_API_KEY=your_azure_api_key_here
AZURE_API_BASE=https://your-resource.openai.azure.com/
AZURE_API_VERSION=2024-02-15-preview

# Cohere Configuration
COHERE_API_KEY=your_cohere_api_key_here

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# ChromaDB collection name
CHROMA_COLLECTION=coda_repo

# =============================================================================
# DOCKER CONFIGURATION
# =============================================================================

# Docker image name for testing sandbox
DOCKER_IMAGE=coda-sandbox

# Docker network mode for security
DOCKER_NETWORK=none

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================

# Embedding model for vector search
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# =============================================================================
# GIT CONFIGURATION
# =============================================================================

# Default branch for repository operations
DEFAULT_BRANCH=main
